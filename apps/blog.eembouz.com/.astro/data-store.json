[["Map",1,2,9,10,19,92,27,138],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.12.3","content-config-digest","01c8a6d71fa8579e","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://blog.eembouz.com/\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/noop\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":false},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"rawEnvValues\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,32,33,46,47,62,63,78,79],"histoire-du-design-graphique",{"id":11,"data":13,"body":28,"filePath":29,"digest":30,"deferredRender":31},{"title":14,"isDraft":15,"taxonomies":16,"thumbnail":22,"summary":23,"pubDate":24,"author":25},"Histoire du design graphique",false,[17,20],{"id":18,"collection":19},"digital-ux-ui-design","taxonomies",{"id":21,"collection":19},"graphic-design","/new_thumbnail.png","Avant d’être un art de vendre, le design graphique a été un art de rassembler, de dominer, parfois de faire peur.",["Date","2025-07-01T00:00:00.000Z"],{"id":26,"collection":27},"elysee","authors","\u003Cdiv class=\"blog-single\">\r\n\r\n\u003Cblockquote>\r\n  **Avant d’être un art de vendre, le design graphique a été un art de\r\n  rassembler, de dominer, parfois de faire peur.**\r\n\u003C/blockquote>\r\n\r\n**Des boucliers romains aux blasons médiévaux, des drapeaux révolutionnaires aux\r\ninsignes militaires du XXe siècle,** chaque symbole, chaque couleur, chaque forme\r\nservait un message : \"Nous sommes unis\", \"Nous sommes puissants\", \"Nous sommes\r\ndifférents\". Ces signes visuels portaient déjà les fonctions que l’on attribue\r\naujourd’hui au design graphique : identité, message, stratégie.\r\n\r\n**Aujourd’hui, je vous propose un voyage à travers l’histoire du design\r\ngraphique.**  \r\nVéritable socle de toute activité visuelle et de toute expérience commerciale, il\r\nsert autant à renforcer l’image de marque d’une entité ou d’une collectivité sociale\r\nqu’à orienter notre manière de percevoir, de classer et de juger ce qui nous entoure.\r\n\r\nDans cet article, nous découvrirons quelques mouvements artistiques majeurs\r\nqui ont non seulement façonné l’histoire du design graphique, mais qui\r\ncontinuent d’inspirer les créateurs d’aujourd’hui.\r\n\r\n## Arts and Crafts\r\n\r\n\u003Cbr />\r\n\u003Cimg\r\n  src=\"/images/arts-craft-movement-william-morris-13.jpg\"\r\n  alt=\"Arts & Crafts\"\r\n/>\r\n\r\nLe **mouvement Arts & Crafts**, né dans les années 1860 au\r\nRoyaume-Uni, a été une **réaction directe contre la mécanisation et la production de masse** apportées par la Révolution industrielle.\r\n\r\nSon objectif était de **réhabiliter le travail artisanal**, la\r\nqualité des matériaux, la beauté de l’objet fait main, et l’unité entre\r\nl’artiste, l’artisan et l’objet.\r\n\r\nAujourd'hui, ce courant se reflète dans le minimalisme, le travail fait main\r\net maison, ainsi que dans l'utilisation de matériaux locaux, écologiques et\r\ndurables.\r\n\r\n## Art Nouveau\r\n\r\nL’**Art Nouveau** est un mouvement artistique né à la fin du XIXe\r\nsiècle, dans la continuité d’**Arts & Crafts**, et partageant une\r\nmême volonté de rupture avec l’industrialisation et la reproduction académique\r\ndes styles anciens.\r\n\r\nIl se caractérise par l’usage de **motifs floraux**, **formes organiques** et **lignes courbes**, qui traduisent une recherche d’harmonie entre l’homme, la nature et l’art. Ce style visait à **intégrer l’art dans le quotidien**, en rendant beaux et expressifs les objets les plus utilitaires. Dans l’imaginaire collectif, l’Art Nouveau incarne **l’élan de modernité** et **l’épanouissement d’un homme nouveau**, à l’aube du XXe siècle.\r\n\r\n\u003Cbr />\r\n\u003Cimg\r\n  src=\"/images/Tile_panel_flowers_Louvre_OA3919-2-297.jpg\"\r\n  alt=\"Art Nouveau 1\"\r\n/>\r\n\u003Cimg src=\"/images/Art_Nouveau_composition.jpg\" alt=\"Art Nouveau 2\" />\r\n\r\n## Constructivisme russe\r\n\r\n\u003Cbr />\r\n\u003Cimg\r\n  src=\"/images/Alexander-Rodchenko-Books-1924.-Image-via-analogue76.com_.webp\"\r\n  alt=\"Constructivisme russe\"\r\n/>\r\n\r\nLe **constructivisme russe** est un mouvement artistique né dans\r\nles années 1910-1920 en Russie, dans le contexte tumultueux de la **Révolution d’Octobre**. Contrairement aux courants précédents, il\r\nrejette toute forme de représentation figurative ou décorative, au profit de **formes géométriques strictes**, d’une\r\n**structure claire**, et d’une esthétique\r\n**fonctionnelle**.\r\n\r\nCe mouvement considère l’œuvre d’art comme un **\"objet construit\"**, une sorte de squelette en trois dimensions au service de la société. Il prône un art **utile**, orienté vers l’ **industrie**, l’**architecture** et la\r\n**propagande** et les **médias de masse**.\r\n\r\n### Héritage contemporain : le design brutaliste sur le web\r\n\r\nL’esthétique du **constructivisme russe** a profondément\r\ninfluencé ce qu’on appelle aujourd’hui le **design brutaliste**,\r\nparticulièrement visible sur certains sites web contemporains (mon site).\r\n\r\nCe style brutaliste, tout comme le constructivisme, **rejette les conventions esthétiques dominantes**, et privilégie des choix **radicaux, fonctionnels et sans fioritures** :\r\n\r\n- typographies très marquées,\r\n- blocs rigides,\r\n- couleurs franches,\r\n- absence de hiérarchisation \"classique\" de l’information,\r\n- et navigation parfois délibérément déroutante.\r\n\r\n**Objectif** : choquer, interpeller, s’affranchir du \"web lisse\" pour\r\nproposer une **expérience brute et assumée**, presque militante.\r\n\r\n## Bauhaus\r\n\r\n\u003Cbr />\r\n\r\n\u003Cimg src=\"/images/616zajxgtRL.jpg\" alt=\"Bauhaus\" />\r\n\r\nLe **Bauhaus** est un mouvement artistique et une école de design\r\nfondée en **1919 à Weimar, en Allemagne**, par l’architecte **Walter Gropius**. Il est souvent considéré comme **le socle du design moderne**, à la croisée de l’ **art**, de l’**architecture** et de l’ **industrie**.\r\n\r\n### Objectif\r\n\r\nL’idée principale du Bauhaus était de **réconcilier l’art et l’artisanat** dans une ère dominée par l’industrialisation. Au lieu d’opposer les deux, le Bauhaus cherchait à les unifier pour créer des objets à la fois **fonctionnels**, **esthétiques**, et **accessibles au plus grand nombre**.\r\n\r\n\u003Cblockquote>\r\n  \"La forme suit la fonction\" devient l’un de leurs principes-clés.\r\n\u003C/blockquote>\r\n\r\n### Caractéristiques\r\n\r\n- Formes **géométriques simples**\r\n- Couleurs **primaires**\r\n- Absence de fioritures\r\n- Priorité à **l’usage** plutôt qu’à la décoration\r\n- Conception d’objets du **quotidien** (meubles, affiches,\r\n  bâtiments)\r\n\r\n### Héritage\r\n\r\nLe Bauhaus a influencé **le graphisme, l’architecture, la typographie** et même **l’urbanisme**. Aujourd’hui, on retrouve son esprit dans des interfaces minimalistes, des polices géométriques, des logos simples, ou encore dans les meubles IKEA.\r\n\r\n## Style international (Swiss Style)\r\n\r\n\u003Cbr />\r\n\u003Cimg src=\"/images/Dessau_bauhaus_04.jpg\" alt=\"Style international\" />\r\n\r\nLe **Style international**, aussi appelé **Swiss Style**, est un courant graphique né en Suisse dans les années 1950. Il hérite des principes du **Bauhaus** et se distingue par une approche **rigoureuse, fonctionnelle et minimaliste** du design.\r\n\r\nCe style repose sur l’usage de **grilles**, de **typographies sans empattement** (comme **Helvetica**) et d’une **hiérarchie visuelle claire**. L’objectif est de transmettre l’information de manière **neutre** **efficace** et **lisible**, sans ornement superflu.\r\n\r\nCe courant a profondément influencé le design éditorial, l’affiche moderne, la\r\nsignalétique, et plus tard, le **webdesign** et les **interfaces numériques**.\r\n\r\n### Éléments clés :\r\n\r\n- Grille de mise en page\r\n- Typographie sans-serif (Helvetica, Univers…)\r\n- Simplicité, clarté, hiérarchie\r\n- Formes géométriques\r\n- Équilibre entre texte et image\r\n\r\n## Pop Art\r\n\r\n\u003Cbr />\r\n\u003Cimg src=\"/images/girl-pop-art-canvas-695502_1600x.webp\" alt=\"Pop Art\" />\r\n\r\nLe **Pop Art** se reconnaît par ses **couleurs vives**, ses **formes simples** et l’usage d’ **images populaires** comme celles de la pub, des emballages ou des BD.\r\n\r\nIl casse les codes en utilisant des éléments du quotidien pour créer un art\r\naccessible et percutant.\r\n\r\nAujourd’hui, on retrouve son influence dans le **design graphique**, la **publicité**, ou encore les **réseaux sociaux**, où l’image forte et directe est au centre de la communication.\r\n\r\n## Postmodernisme\r\n\r\n\u003Cbr />\r\n\u003Cimg\r\n  src=\"/images/360_F_973913124_ExyhYfl8rIzVqbwKjT7CH3N9fnRzOJUA.jpg\"\r\n  alt=\"Postmodernisme\"\r\n/>\r\n\r\nLe **postmodernisme** apparaît vers les années **1970**, en réaction au modernisme et à ses formes trop strictes, froides et parfois jugées trop sérieuses.\r\n\r\nIl casse les règles : **mélange les styles**, **joue avec les couleurs**, **reprend le passé** tout en y ajoutant une touche d’humour ou de décalage. C’est un courant qui refuse de suivre une seule voie.\r\n\r\nEn architecture, design ou graphisme, le postmodernisme remet en cause l’idée\r\nde “bon goût” et valorise **la liberté d’expression**, même si\r\ncela choque ou surprend.\r\n\r\nAujourd’hui, on en voit encore les traces dans des créations **originales, colorées et inattendues**, qui mélangent époques et influences.\r\n\r\n## En résumé\r\n\r\n- **Arts & Crafts (1860s)** :  \r\n   Retour au fait main, réaction contre l’industrialisation.\r\n\r\n- **Art Nouveau (fin XIXe – début XXe)** :  \r\n   Lignes courbes, nature, harmonie\r\n\r\n- **Constructivisme russe (1910s–1920s)** :  \r\n   Formes géométriques, propagande visuelle.\r\n\r\n- **Bauhaus (1919–1933)** :  \r\n   Fonctionnalité, simplicité, union art et industrie.\r\n\r\n- **Style international (1920s–1980s)** :  \r\n   Architecture moderne, acier, verre, épure.\r\n\r\n- **Style typographique suisse / Style suisse (années 1950)** :  \r\n   Grille, typographie claire, Helvetica, influence majeure en graphisme.\r\n\r\n- **Pop Art (1950s–1970s)** :  \r\n   Couleurs vives, culture de masse, Andy Warhol.\r\n\r\n- **Postmodernisme (1970s–1990s)** :  \r\n   Rupture avec le modernisme, mélange des styles.\r\n\r\n**Du travail artisanal aux créations numériques, le design graphique a sans\r\ncesse évolué pour refléter son époque.**  \r\nChaque mouvement raconte une histoire, révèle une vision du monde, et influence\r\nencore aujourd’hui notre manière de communiquer. Comprendre cette histoire nous\r\naide à mieux saisir les défis actuels et à imaginer l’avenir du design, toujours\r\nen quête d’innovation et de sens.\r\n\r\n\u003C/div>","src/data/blog/histoire-du-design-graphique.mdx","7ca28afafd357670",true,"load-balancer",{"id":32,"data":34,"body":43,"filePath":44,"digest":45,"deferredRender":31},{"title":35,"isDraft":15,"taxonomies":36,"thumbnail":39,"summary":40,"pubDate":41,"author":42},"Le Load Balancer",[37],{"id":38,"collection":19},"infrastructure-reseaux","/load_balancer/load_balancer.png","Le load balancing, ou équilibrage de charge, est une technique utilisée pour améliorer la disponibilité, la scalabilité et la résilience des applications web modernes en répartissant le trafic entre plusieurs serveurs.",["Date","2025-07-21T00:00:00.000Z"],{"id":26,"collection":27},"\u003Cdiv class=\"blog-single\">\r\n\r\nChaque jour, des milliers d’utilisateurs se connectent pour consulter leurs\r\ne-mails, échanger des messages ou travailler sur leurs projets. Un nombre\r\nincalculable de paquets réseau transitent chaque seconde entre des milliers de\r\nserveurs, tous optimisés pour répondre le plus rapidement possible et\r\ndistribuer efficacement les ressources.\r\n\r\nMais qui dit **multiplication des utilisateurs**, dit aussi **requêtes\r\nsimultanées**, risques de surcharge, lenteurs, voire pannes.\r\n\r\nDans cette course à la performance et à la réactivité, de nombreuses techniques\r\nsont mises en œuvre pour garantir une distribution fluide et équilibrée de la\r\ncharge : **le load balancing** en est l’une des clés.\r\n\r\n**Le Load Balancing** est un processus clé en informatique, souvent utilisé\r\ndans l’architecture des systèmes distribués. Il permet de répartir un ensemble\r\nde tâches ou de requêtes sur plusieurs ressources (comme des serveurs) afin de\r\n**réduire la surcharge**, **améliorer les performances globales** et\r\n**garantir une haute disponibilité**. Il s’applique principalement **au niveau\r\ndes protocoles d’application** tels que **HTTP/HTTPS, FTP, SMTP, DNS, SSH**,\r\netc., pour gérer efficacement le trafic réseau.\r\n\r\n\u003Cbr />\r\n\u003Cimg\r\n  src=\"/load_balancer/illustration_load-balancer.png\"\r\n  alt=\"Schéma d'un load balancer distribuant le trafic\"\r\n/>\r\n\r\nConcrètement, au lieu que chaque client s’adresse directement à un serveur\r\ndonné, toutes les requêtes sont envoyées à une **adresse réseau centrale** —\r\ncelle du load balancer. Celui-ci se charge alors de **rediriger le trafic**\r\nvers les serveurs disponibles, selon différents critères (algorithmes, charge\r\nactuelle, disponibilité, etc.).\r\n\r\nCe mécanisme permet d’éviter les surcharges, d’améliorer les performances globales du système et de garantir une haute disponibilité du service.\r\n\r\n## Load Balancing : niveau 4 vs niveau 7\r\n\r\nIl existe plusieurs types de load balancers, selon le niveau du **modèle OSI** sur\r\nlequel ils opèrent :\r\n\r\n- **Niveau 4 (transport)** : l’équilibrage se fait sur la base des adresses IP, des ports TCP ou UDP. Le load balancer ne « voit » pas le contenu des requêtes, il se contente de router le trafic selon des règles de bas niveau.  \r\n   Exemple : **HAProxy** ou **AWS Network Load Balancer**.\r\n- **Niveau 7 (application)** : l’équilibrage se fait en analysant le contenu des requêtes HTTP, comme l’URL, les cookies, ou les en-têtes. Cela permet une répartition plus fine et contextuelle.  \r\n   Exemple : **NGINX**, **Traefik**, ou **AWS Application Load Balancer**.\r\n\r\nCe choix dépend du type d’application, du besoin en personnalisation et des performances attendues.\r\n\r\n## Principaux algorithmes d’équilibrage:\r\n\r\n### Le Round Robin DNS :\r\n\r\n\u003Cbr />\r\n\u003Cimg src=\"/load_balancer/round_robin.png\" alt=\"round_rogin\" />\r\n\r\nLe **Round Robin DNS** est un algorithme d’équilibrage de charge qui permet de\r\nrépartir le trafic entre plusieurs serveurs en associant **plusieurs adresses\r\nIP** à un **même nom de domaine**.\r\n\r\nContrairement à d'autres méthodes, cette technique **ne nécessite aucun\r\néquipement physique** dédié. Elle repose sur le fonctionnement du **serveur\r\nDNS autoritaire** ([authoritative\r\nnameserver](https://www.cloudflare.com/learning/dns/dns-server-types/#authoritative-nameserver)).\r\n\r\nElle est facile à mettre en place via l’interface de gestion DNS de votre fournisseur :\r\n\r\n- en ajoutant **plusieurs enregistrements A** (pour IPv4),\r\n- ou des **enregistrements AAAA** (pour IPv6).\r\n\r\n**Avantage** : simplicité de configuration.  \r\n**Limite** : pas de gestion intelligente de la charge réelle (le DNS ne “voit” pas si un serveur est saturé ou indisponible).\r\n\r\n## load balancers logiciels et matériels:\r\n\r\n## -- logicielles:\r\n\r\n\u003Cbr />\r\n\r\n### [Nginx](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/) :\r\n\r\n\u003Cbr />\r\n\r\nnginx est un logiciel open-source qui fait office de **serveur web**, de\r\n**reverse proxy** et de **load balancer**. Il est reconnu pour sa **faible\r\nconsommation mémoire** et sa **grande rapidité**, ce qui en fait un choix\r\nprivilégié dans les environnements à fort trafic.\r\n\r\nPour configurer Nginx comme load balancer, on utilise la directive `upstream` dans le fichier de configuration, qui permet de déclarer plusieurs serveurs backend :\r\n\r\n```nginx\r\nhttp {\r\n    upstream backend_servers {\r\n        server backend1.example.com;\r\n        server backend2.example.com;\r\n        server backend3.example.com;\r\n    }\r\n\r\n    server {\r\n        listen 80;\r\n\r\n        location / {\r\n            proxy_pass http://backend_servers;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nPar défaut, Nginx applique le **round robin**, mais il supporte aussi :\r\n\r\n- `least_conn` : vers le serveur avec le moins de connexions actives\r\n- `ip_hash` : pour garder la session sur le même serveur\r\n\r\n## choisir une méthode d’équilibrage de charge:\r\n\r\n[NGINX](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#choosing-a-load-balancing-method \"Choosing a Load Balancing Method\") en charge quatre méthodes d'équilibrage de charge : Round Robin, Least Connections, IP Hash et Generic Hash.\r\n\r\n> **Note:** Lors de la configuration d'une méthode autre que Round Robin, mettez la directive correspondante ([`hash`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#hash), [`ip_hash`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash), [`least_conn`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn), [`least_time`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_time), ou [`random`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#random)) au-dessus de la liste de `server` directives dans le [`upstream {}`](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream) bloc.\r\n\r\n1- **Round Robin (Default)**\r\n\r\n```nginx\r\nupstream backend {\r\n   # no load balancing method is specified for Round Robin\r\n   server backend1.example.com;\r\n   server backend2.example.com;\r\n}\r\n```\r\n\r\n    Contrairement au Round Robin DNS, les reverse proxies comme **NGINX** permettent un équilibrage de charge **plus intelligent** et dynamique, avec prise en compte des connexions actives, de l’adresse IP du client, ou de la clé de hachage.\r\n\r\n2- **[Least\r\nConnections](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn) –**\r\n Une requête est envoyée au serveur avec le moins de connexions actives. Cette\r\nméthode prend également [poids du\r\nserveur](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#weights) en\r\nconsidération.\r\n\r\n```nginx\r\nupstream backend {\r\n    least_conn;\r\n    server backend1.example.com;\r\n    server backend2.example.com;\r\n}\r\n```\r\n\r\n3- **[IP\r\nHash](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash) –**\r\nLe serveur auquel une requête est envoyée est déterminé à partir de l'adresse\r\nIP du client. Dans ce cas, soit les trois premiers octets de l'adresse IPv4,\r\nsoit l'adresse IPv6 entière sont utilisés pour calculer la valeur de hachage.\r\nLa méthode garantit que les requêtes provenant de la même adresse parviennent\r\nau même serveur, sauf si celui-ci n'est pas disponible.\r\n\r\n```nginx\r\nupstream backend {\r\n    ip_hash;\r\n    server backend1.example.com;\r\n    server backend2.example.com;\r\n}\r\n```\r\n\r\nSi l'un des serveurs doit être temporairement retiré de la rotation de\r\nchargement‑équilibrage, il peut être marqué avec\r\nle [down](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#down) paramètre.\r\nCela préserve le hachage actuel des adresses IP des clients. Les requêtes qui\r\ndevaient être traitées par ce serveur sont automatiquement envoyées au serveur\r\nsuivant du groupe.\r\n\r\n```nginx\r\nupstream backend {\r\n    server backend1.example.com;\r\n    server backend2.example.com;\r\n    server backend3.example.com down;\r\n}\r\n```\r\n\r\n4- **Generic [Hash](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#hash) –**\r\nLe serveur auquel une requête est envoyée est déterminé à partir d'une clé\r\ndéfinie par l'utilisateur‑. Cette clé peut être une chaîne de texte, une\r\nvariable ou une combinaison. Par exemple, la clé peut être une adresse IP\r\nsource et un port appariés. Cet exemple utilise un URI :\r\n\r\n```nginx\r\nupstream backend {\r\n    hash $request_uri consistent;\r\n    server backend1.example.com;\r\n    server backend2.example.com;\r\n}\r\n```\r\n\r\n    L'optionnel [cohérent](https://nginx.org/en/docs/http/ngx_http_upstream_module.html#hash) paramètre au `hash` la directive permet [ketama](http://www.last.fm/user/RJ/journal/2007/04/10/rz_libketama_-_a_consistent_hashing_algo_for_memcache_clients) cohérent‑équilibrage de charge de hachage. Les requêtes sont réparties uniformément sur tous les serveurs en amont en fonction de la valeur de clé hachée définie par l'utilisateur‑. Si un serveur en amont est ajouté ou supprimé d'un groupe en amont, seules quelques clés sont remappées, ce qui minimise les échecs de cache. Ceci est utile pour équilibrer la charge des serveurs de cache ou d’autres applications qui accumulent de l’état.\r\n\r\n### [HAProxy](https://www.haproxy.com/blog/haproxy-configuration-basics-load-balance-your-servers):\r\n\r\nHAProxy est un logiciel gratuit et open source qui offre une haute disponibilité et un équilibrage de charge pour les applications basées sur TCP et HTTP. Il répartit le trafic réseau entrant sur plusieurs serveurs pour garantir une utilisation et une évolutivité optimales.\r\n\r\n**HAProxy** et **NGINX** peuvent tous deux faire de l’équilibrage de charge,\r\nmais ils ont des **différences importantes** dans leur conception, leur\r\ncomportement et leurs cas d’usage préférés.\r\n\r\n## NGINX vs HAProxy : Comparaison d’usage\r\n\r\n\u003Cdiv class=\"table-container\">\r\n\r\n| Critère                      | **NGINX**                           | **HAProxy**                              |\r\n| ---------------------------- | ----------------------------------- | ---------------------------------------- |\r\n| **Fonction principale**      | Serveur HTTP + reverse proxy        | Load balancer (spécialisé)               |\r\n| **Performance brute**        | Excellente en HTTP, bon généraliste | Meilleure sur les charges réseau élevées |\r\n| **Équilibrage niveau**       | L7 (HTTP) + partiel L4              | L4 (TCP) + L7 (HTTP) très optimisé       |\r\n| **Support HTTPS natif**      | Oui (certbot, etc.)                 | Possible, mais plus complexe             |\r\n| **Configuration**            | Simple, fichiers de config lisibles | Plus verbeux mais très précis            |\r\n| **Monitoring / stats**       | Basique (module de status)          | Très détaillé (dashboard intégré)        |\r\n| **Utilisation fréquente**    | Reverse proxy web, CDN, cache       | Load balancing pur, haute disponibilité  |\r\n| **Consommation mémoire**     | Faible                              | Ultra-optimisée aussi                    |\r\n| **Hot reload / live update** | Pas toujours sans coupure           | Oui, sans perturber les connexions       |\r\n\r\n\u003C/div>\r\n\r\n## Load Balancer matériel\r\n\r\n    En support physique, En version matérielle, ce sont des dispositifs physiques installés dans des datacenters spécifiques. Bien qu'il soient capable de gérer et dispatcher un grand volume de trafic sur différent réseau, Ils offrent moins de flexibilité et leurs coûts sont assez élevés.\r\n\r\n\u003Cdiv class=\"table-container\">\r\n\r\n| Nom                             | Description                                                                                                                            |\r\n| ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\r\n| **F5 BIG-IP**                   | Le plus connu. Très utilisé en entreprise. Permet du L4 et L7 avec des fonctions avancées (SSL offloading, firewall applicatif, etc.). |\r\n| **Cisco ACE / ACI**             | Intégré dans les solutions réseau Cisco. Moins courant aujourd’hui, mais très robuste dans certains data centers.                      |\r\n| **Barracuda Load Balancer ADC** | Connu pour sa simplicité, bon rapport qualité/prix, adapté aux PME. Propose aussi des fonctions de sécurité.                           |\r\n\r\n\u003C/div>\r\n\r\n---\r\n\r\n> Dans cet article, nous avons clarifié et expliqué quelques-uns des algorithmes de **load balancing** les plus utilisés.  \r\n> Mais cette liste est loin d’être exhaustive : des outils comme **HAProxy** proposent d'autres méthodes avancées de répartition, ainsi que des fonctionnalités clés telles que :\r\n>\r\n> - les **health checks** (vérification automatique de l’état des serveurs),\r\n> - la **redondance** avec des load balancers en mode **actif/passif**,\r\n> - la **reprise automatique** en cas de panne.\r\n>\r\n> De leur côté, des solutions commerciales comme **NGINX Plus** offrent également des fonctionnalités étendues, incluant une gestion fine des sessions, des métriques en temps réel, ou encore le support natif de protocoles spécifiques.\r\n\r\nEn résumé, le **load balancing** est un composant essentiel des architectures modernes, garantissant **performance, fiabilité et scalabilité**. Qu’il soit implémenté par des solutions logicielles comme **NGINX** ou **HAProxy**, ou par du matériel spécialisé, il joue un rôle de chef d’orchestre entre les utilisateurs et les serveurs. Le choix du bon algorithme ou de la bonne solution dépendra toujours du **contexte d’usage**, du **budget**, et des **contraintes techniques**.\r\n\r\n\u003C/div>","src/data/blog/load-balancer.mdx","964bb608ae21f68d","qu-est-ce-que-design-pattern",{"id":46,"data":48,"body":59,"filePath":60,"digest":61,"deferredRender":31},{"title":49,"isDraft":15,"taxonomies":50,"thumbnail":55,"summary":56,"pubDate":57,"author":58},"Qu’est-ce qu’un design pattern ?",[51,53],{"id":52,"collection":19},"bonnes-pratiques-clean-code",{"id":54,"collection":19},"programmation","/design_pattern.png","Les design patterns sont des solutions éprouvées et validées par les pionniers de l’informatique. Ils ont été conçus pour structurer et organiser le code de manière claire, lisible et efficace.",["Date","2025-07-12T00:00:00.000Z"],{"id":26,"collection":27},"import BlockDesignPattern from \"../../components/blog/pattern/BlockDesignPattern.tsx\";\r\nimport DisplayList from \"../../components/blog/pattern/DisplayList.tsx\";\r\n\r\n\u003Cdiv class=\"blog-single\">\r\n\r\nLes **design patterns** sont des solutions éprouvées et validées par les\r\npionniers de l'informatique. Ils ont été conçus pour **structurer et organiser\r\nle code** de manière claire, lisible et efficace. L’idée est de proposer des\r\n**modèles génériques et réutilisables**, qui facilitent la **scalabilité** et\r\nla **maintenance** des systèmes logiciels, tout en réduisant les erreurs\r\ncourantes.\r\n\r\n## histoire\r\n\r\nLes **design patterns** sont nés de la volonté de produire du code\r\n**scalable** et maintenable, même si cela signifiait, au départ, **sacrifier\r\nun peu de confort de développement**. Lorsque les équipes techniques\r\nremarquent qu’une même structure ou solution est **répétée plusieurs fois dans\r\nle code** pour résoudre un même type de problème, elles finissent par lui\r\ndonner un **nom commun**. C’est ainsi qu’est née l’idée des **design\r\npatterns** : des solutions **nommées, génériques et réutilisables**,\r\ndocumentées pour faciliter la collaboration et la compréhension dans les\r\nprojets logiciels.\r\n\r\n\u003Cblockquote>\r\n  \u003Cp>\r\n    \u003Cem>\r\n      historiquement, Le concept de design pattern est inspiré du travail de\r\n      **Christopher Alexander** dans l’architecture, puis formalisé en\r\n      informatique par les **\"Gang of Four\"** en 1994. Ces patterns sont devenus\r\n      une base incontournable pour structurer le code, éviter les redondances,\r\n      et faciliter la maintenance des applications à grande échelle.\r\n    \u003C/em>\r\n  \u003C/p>\r\n\u003C/blockquote>\r\n\r\n## Pourquoi devrais je apprendre des modèles ?\r\n\r\nDans la majorité des cas, vous avez probablement déjà **utilisé des design\r\npatterns sans le savoir**. C’est exactement ce qui distingue souvent un\r\ndéveloppeur junior d’un développeur senior : la capacité à reconnaître,\r\ncomprendre et appliquer consciemment ces structures. Par exemple, le **code\r\nsource des Framework** (comme React, Laravel, AdonisJS, etc.) en est truffé.\r\n\r\nUne fois maîtrisés, les **design patterns** deviennent une véritable **boîte à\r\noutils** pour résoudre efficacement des problèmes courants en développement.\r\nIls vous aideront à **penser autrement**, avec plus de structure et de recul.\r\nAvec le temps, cette manière de réfléchir deviendra presque naturelle.\r\n\r\n## Classifications et Rôle:\r\n\r\nCette liste n’est pas exhaustive et ne couvre pas l’ensemble des design\r\npatterns que vous pourriez rencontrer. Nous allons nous concentrer sur un type\r\nparticulier de modèles : les **modèles architecturaux**.\r\n\r\nCes modèles peuvent être implémentés dans **n’importe quel langage de\r\nprogrammation** et sont appelés **modèles universels** ou **patterns de haut\r\nniveau**. Ils s’opposent aux **idiomes**, qui sont des solutions plus\r\nspécifiques, propres à un langage particulier et souvent de bas niveau.\r\n\r\n\u003Cblockquote>\r\n  \u003Cp>\r\n    - Les **patterns architecturaux** définissent la structure globale d’une\r\n    application ou d’un système (ex. MVC, Client-Serveur, Microservices).\r\n  \u003C/p>\r\n  \u003Cp>\r\n    - Les **patterns de conception** (design patterns au sens plus classique)\r\n    concernent l’organisation du code à l’intérieur des composants (ex.\r\n    Singleton, Factory, Observer).\r\n  \u003C/p>\r\n  \u003Cp>\r\n    - Les **idiomes** sont des constructions propres à un langage, qui\r\n    exploitent ses spécificités syntaxiques et sémantiques.\r\n  \u003C/p>\r\n\u003C/blockquote>\r\n\r\n\u003CDisplayList client:only />\r\n\r\n---\r\n\r\n## Cas concret : un store Zustand refactoré selon les Design Patterns\r\n\r\nPour illustrer concrètement l’intérêt des design patterns, prenons un\r\n**exemple réel** rencontré lors de la construction de mon application.\r\nJ’utilise Zustand comme **solution de gestion d’état** globale. C’est un outil\r\nsimple, mais très puissant, qui permet de construire un store à la volée.\r\n\r\nCependant, en avançant dans le développement, le store devient **complexe,\r\ndifficile à tester ou à maintenir**, et certaines logiques sont dupliquées.\r\nC’est exactement le genre de situation où **les design patterns prennent tout\r\nleur sens**.\r\n\r\nDans cette section, nous allons **refactorer ce store pas à pas**, en\r\nappliquant différents design patterns. Chaque refactor sera **associé à un\r\npattern précis** : Singleton, Factory, Observer, etc. Cela permettra de\r\ncomprendre **à la fois la théorie** derrière chaque modèle **et son\r\napplication pratique** dans un contexte moderne (React + Zustand).\r\n\r\n## Le code de base\r\n\r\nAvant de commencer le refactor, voici **le store Zustand tel qu’il existait\r\ninitialement** dans mon projet. Il est fonctionnel, et implémentait\r\ncertainspattern partiellement\r\n\r\n- Factory Method (partiellement)\r\n- Strategy\r\n\r\n```ts\r\nimport { UnAuthenticatedError } from \"@helpers/website\";\r\n\r\nimport {\r\n  createContext,\r\n  useContext,\r\n  useMemo,\r\n  type PropsWithChildren,\r\n} from \"react\";\r\n\r\nimport { create, useStore as useZustandStore } from \"zustand\";\r\n\r\nimport { combine, persist } from \"zustand/middleware\";\r\n\r\nimport type { Account } from \"./hooks/useAuth.ts\";\r\n\r\nimport type {\r\n  AccessLevels,\r\n  Courses,\r\n  Difficulties,\r\n  Statuses,\r\n} from \"@api/website/types\";\r\n\r\nexport type ResourceMap = {\r\n  accessLevel: AccessLevels;\r\n\r\n  difficulties: Difficulties;\r\n\r\n  statuses: Statuses;\r\n};\r\n\r\ntype State = {\r\n  account: undefined | null | Record\u003Cstring, any>;\r\n\r\n  organization: Record\u003Cstring, any>;\r\n\r\n  accesslevels: AccessLevels[];\r\n\r\n  difficulties: Difficulties[];\r\n\r\n  statuses: Statuses[];\r\n\r\n  courses: Courses[];\r\n};\r\n\r\nfunction getStateKey\u003CT extends keyof ResourceMap>(\r\n  type: T\r\n): keyof Omit\u003CState, \"account\" | \"organization\" | \"courses\"> {\r\n  switch (type) {\r\n    case \"accessLevel\":\r\n      return \"accesslevels\";\r\n\r\n    case \"difficulties\":\r\n      return \"difficulties\";\r\n\r\n    case \"statuses\":\r\n      return \"statuses\";\r\n\r\n    default:\r\n      throw new Error(\"Courses resource type \" + type);\r\n  }\r\n}\r\n\r\nconst createStore = () =>\r\n  create(\r\n    persist(\r\n      combine(\r\n        {\r\n          account: undefined as undefined | null | Account,\r\n\r\n          organization: {},\r\n\r\n          courses: [],\r\n\r\n          accesslevels: [],\r\n\r\n          difficulties: [],\r\n\r\n          statuses: [],\r\n        } as State,\r\n\r\n        (set) => ({\r\n          setResources: function \u003CT extends keyof ResourceMap>(\r\n            type: T,\r\n\r\n            data: ResourceMap[T][]\r\n          ) {\r\n            const key = getStateKey(type);\r\n\r\n            return set({ [key]: data });\r\n          },\r\n\r\n          addResource: function \u003CT extends keyof ResourceMap>(\r\n            type: T,\r\n\r\n            newData: ResourceMap[T]\r\n          ) {\r\n            const key = getStateKey(type);\r\n\r\n            return set((state) => ({\r\n              [key]: [...state[key], newData],\r\n            }));\r\n          },\r\n\r\n          updateResource: function \u003CT extends keyof ResourceMap>(\r\n            type: T,\r\n\r\n            newData: ResourceMap[T]\r\n          ) {\r\n            const key = getStateKey(type);\r\n\r\n            return set((state) => ({\r\n              [key]: state[key].map((item) =>\r\n                item.id === newData.id ? { ...item, ...newData } : item\r\n              ),\r\n            }));\r\n          },\r\n\r\n          deleteResource: function \u003CT extends keyof ResourceMap>(\r\n            type: T,\r\n\r\n            id: number\r\n          ) {\r\n            const key = getStateKey(type);\r\n\r\n            return set((state) => ({\r\n              [key]: state[key].filter((item) => item.id !== id),\r\n            }));\r\n          },\r\n\r\n          setCourses: (courses: Courses[]) => {\r\n            set({ courses });\r\n          },\r\n\r\n          addCourse: (course: Courses) => {\r\n            set((state) => ({\r\n              courses: [...state.courses, course],\r\n            }));\r\n          },\r\n\r\n          updateOrganization: (newDate: Record\u003Cstring, any>) =>\r\n            set({ organization: newDate }),\r\n\r\n          updateAccount: (account: Account | null) => set({ account }),\r\n        })\r\n      ),\r\n\r\n      {\r\n        name: \"account\",\r\n      }\r\n    )\r\n  );\r\n\r\ntype Store = ReturnType\u003Ctypeof createStore>;\r\n\r\ntype StoreState = Store extends {\r\n  getState: () => infer T;\r\n}\r\n  ? T\r\n  : never;\r\n\r\nconst StoreContext = createContext\u003C{ store?: Store }>({});\r\n\r\nexport function StoreProvider({ children }: PropsWithChildren) {\r\n  const store = useMemo(() => createStore(), []);\r\n\r\n  return (\r\n    \u003CStoreContext.Provider value={{ store: store }}>\r\n            {children}   {\" \"}\r\n    \u003C/StoreContext.Provider>\r\n  );\r\n}\r\n\r\nexport function useStore\u003CT>(selector: (state: StoreState) => T) {\r\n  const store = useContext(StoreContext).store;\r\n\r\n  if (!store) {\r\n    throw new Error(\"A context need to be provider to use the store\");\r\n  }\r\n\r\n  return useZustandStore(store, selector);\r\n}\r\n\r\nexport type InferResourceType\u003CT> = T extends keyof ResourceMap\r\n  ? ResourceMap[T]\r\n  : never;\r\n\r\nexport function useResource\u003CT extends keyof ResourceMap>(type: T) {\r\n  const key = getStateKey(type);\r\n\r\n  const list = useStore((state) => state[key]) as InferResourceType\u003CT>[];\r\n\r\n  const setResources = useStore((state) => state.setResources);\r\n\r\n  const addResource = useStore((state) => state.addResource);\r\n\r\n  const updateResource = useStore((state) => state.updateResource);\r\n\r\n  const deleteResource = useStore((state) => state.deleteResource);\r\n\r\n  return {\r\n    list,\r\n\r\n    set: (data: InferResourceType\u003CT>[]) => setResources(type, data),\r\n\r\n    add: (data: InferResourceType\u003CT>) => addResource(type, data),\r\n\r\n    update: (data: InferResourceType\u003CT>) => updateResource(type, data),\r\n\r\n    delete: (id: number) => deleteResource(type, id),\r\n  };\r\n}\r\n\r\n// ACCESS_LEVELS\r\n\r\nexport function useAccessLevels() {\r\n  return useResource(\"accessLevel\");\r\n}\r\n\r\n// DIFFICULTIES\r\n\r\nexport function useDifficulties() {\r\n  return useResource(\"difficulties\");\r\n}\r\n\r\n// STATUSES\r\n\r\nexport function useStatuses() {\r\n  return useResource(\"statuses\");\r\n}\r\n\r\n// COURSES\r\n\r\nexport function useCourses() {\r\n  const list = useStore((state) => state.courses);\r\n\r\n  const setCourses = useStore((state) => state.setCourses);\r\n\r\n  const addCourses = useStore((state) => state.addCourse);\r\n\r\n  console.log(list);\r\n\r\n  return {\r\n    list,\r\n\r\n    set: (data: Courses[]) => setCourses(data),\r\n\r\n    add: (data: Courses) => addCourses(data),\r\n  };\r\n}\r\n\r\n// ORGANISATION\r\n\r\nexport function useOrganization() {\r\n  return useStore((state) => state.organization);\r\n}\r\n\r\nexport function useUpdateOrganization() {\r\n  return useStore((state) => state.updateOrganization);\r\n}\r\n\r\nexport function useUpdateAccount() {\r\n  return useStore((state) => state.updateAccount);\r\n}\r\n\r\nexport function useIsAuth() {\r\n  const account = useStore((state) => state.account);\r\n\r\n  if (!account) {\r\n    throw new UnAuthenticatedError();\r\n  }\r\n\r\n  return {\r\n    ...account,\r\n  };\r\n}\r\n\r\nexport function useAccount() {\r\n  const account = useStore((state) => state.account);\r\n\r\n  return {\r\n    ...account,\r\n  };\r\n}\r\n```\r\n\r\n### Objectifs de la version refactorée\r\n\r\n- Séparer les responsabilités.\r\n- Appliquer des patterns classiques.\r\n- Garder une API propre et extensible.\r\n\r\n## Singleton:\r\n\r\nUn singleton s'assure d'avoir qu'une seul instance d'un object (de préférence\r\nune class) ne soit initialisé, offrant ainsi un seul point global\r\nd'initialisation. Dans notre situation nous somme en javascript ou chaque\r\nobject et module est unique dans son contexte d'exécution.\r\n\r\n— **Singleton Pattern**\r\n\r\n```ts\r\nimport { create } from \"zustand\";\r\nimport { combine, persist } from \"zustand/middleware\";\r\nimport type { State, Store, ResourceKey, InferResourceType } from \"./types\";\r\nimport { getStateKey } from \"./factory\";\r\n\r\nlet storeInstance: Store | undefined;\r\n\r\nexport const createStore = (): Store => {\r\n  if (storeInstance) return storeInstance;\r\n\r\n  storeInstance = create(\r\n    persist(\r\n      combine(\r\n        {\r\n          account: undefined,\r\n          organization: {},\r\n          courses: [],\r\n          accesslevels: [],\r\n          difficulties: [],\r\n          statuses: [],\r\n        } as State,\r\n        (set) => ({\r\n          updateAccount: (account) => set({ account }),\r\n          updateOrganization: (org) => set({ organization: org }),\r\n\r\n          setResources: \u003CT extends ResourceKey>(\r\n            type: T,\r\n            data: InferResourceType\u003CT>[]\r\n          ) => set({ [getStateKey(type)]: data }),\r\n\r\n          addResource: \u003CT extends ResourceKey>(\r\n            type: T,\r\n            item: InferResourceType\u003CT>\r\n          ) =>\r\n            set((state) => ({\r\n              [getStateKey(type)]: [...state[getStateKey(type)], item],\r\n            })),\r\n\r\n          updateResource: \u003CT extends ResourceKey>(\r\n            type: T,\r\n            item: InferResourceType\u003CT>\r\n          ) =>\r\n            set((state) => ({\r\n              [getStateKey(type)]: state[getStateKey(type)].map((i) =>\r\n                i.id === item.id ? { ...i, ...item } : i\r\n              ),\r\n            })),\r\n\r\n          deleteResource: \u003CT extends ResourceKey>(type: T, id: number) =>\r\n            set((state) => ({\r\n              [getStateKey(type)]: state[getStateKey(type)].filter(\r\n                (i) => i.id !== id\r\n              ),\r\n            })),\r\n        })\r\n      ),\r\n      { name: \"account\" }\r\n    )\r\n  );\r\n\r\n  return storeInstance;\r\n};\r\n```\r\n\r\nIci on assure qu’un seul store Zustand existe dans l’app, ce qui est important\r\npour éviter les incohérences ou re-rendu inutile dans React `createStore()`\r\ndans le contexte React.\r\n\r\nje ne reviendrais pas sur l'utilisation de Zustand, dans un prochain article.\r\nEn bref :\r\n\r\n- **Combine** : est un middleware qui permet de séparer le state et les actions.\r\n- **Persist** : est un middleware qui permet de faire de la persistance avec le local Storage.\r\n\r\n## factory\r\n\r\n— **Factory Pattern pour les clés**\r\n\r\n```ts\r\nexport const getStateKey = \u003CT extends ResourceKey>(type: T): keyof State => {\r\n  const map: Record\u003CResourceKey, keyof State> = {\r\n    accessLevel: \"accesslevels\",\r\n    difficulties: \"difficulties\",\r\n    statuses: \"statuses\",\r\n  };\r\n  const key = map[type];\r\n  if (!key) throw new Error(`Unknown resource type: ${type}`);\r\n  return key;\r\n};\r\n```\r\n\r\nOn **abstrait la logique** de mappage `\"accessLevel\"` → `\"accesslevels\"` dans\r\nun objet **déclaratif**, au lieu d’un `switch`.\r\n\r\n## Facade\r\n\r\n— **Facade Pattern**\r\n\r\n```ts\r\nexport const useAccount = () => {\r\n  const account = useStore((s) => s.account);\r\n  return { ...account };\r\n};\r\n```\r\n\r\nOn caches la complexité du store et exposes une API simple.\r\n\r\n## Illustrations en pseudo-code\r\n\r\n\u003Cblockquote>\r\n  \u003Cp>\r\n    Bien que cet article ait pour objectif de fournir une **implémentation\r\n    concrète** des design patterns dans un contexte réel (React + Zustand),\r\n    certains modèles comme **Singleton** ou **Factory Method** s’intègrent\r\n    naturellement dans l’architecture de mon store.\r\n    \u003Cbr />\r\n    En revanche, d’autres modèles comme **Builder**, **Strategy** ou\r\n    **Decorator** sont plus **conceptuels** dans ce contexte. Ils seront donc\r\n    illustrés de manière plus **générique en pseudo-code** pour faciliter leur\r\n    compréhension.\r\n    \u003Cbr />\r\n    Ces exemples ne sont **pas destinés à être copiés tels quels** dans un\r\n    projet Zustand ou React, mais plutôt à vous aider à **saisir l’idée\r\n    générale** derrière chaque pattern.\r\n    \u003Cbr />\r\n    Vous verrez ensuite comment **adapter ces concepts** dans un projet réel si\r\n    nécessaire.\r\n  \u003C/p>\r\n\u003C/blockquote>\r\n\r\n### Builder (construire un objet étape par étape)\r\n\r\n\u003Cbr />\r\n\r\n```ts\r\nclass CourseBuilder {\r\n  name = \"\";\r\n  color = \"\";\r\n\r\n  setName(name: string) {\r\n    this.name = name;\r\n    return this;\r\n  }\r\n\r\n  setColor(color: string) {\r\n    this.color = color;\r\n    return this;\r\n  }\r\n\r\n  build() {\r\n    return { name: this.name, color: this.color };\r\n  }\r\n}\r\n\r\nconst course = new CourseBuilder().setName(\"React\").setColor(\"blue\").build();\r\n```\r\n\r\n### Strategy (changer de comportement dynamiquement)\r\n\r\n\u003Cbr />\r\n\r\n```ts\r\nclass ExportStrategy {\r\n  execute(data) {\r\n    throw \"Not implemented\";\r\n  }\r\n}\r\n\r\nclass JsonExport extends ExportStrategy {\r\n  execute(data) {\r\n    return JSON.stringify(data);\r\n  }\r\n}\r\n\r\nclass CsvExport extends ExportStrategy {\r\n  execute(data) {\r\n    return data.map((row) => row.join(\",\")).join(\"\\n\");\r\n  }\r\n}\r\n\r\nfunction exportData(data, strategy: ExportStrategy) {\r\n  return strategy.execute(data);\r\n}\r\n```\r\n\r\n### Decorator (enrichir un comportement sans toucher au code source)\r\n\r\n\u003Cbr />\r\n\r\n```ts\r\nfunction withLogger(fn) {\r\n  return function (...args) {\r\n    console.log(\"Appel de\", fn.name, \"avec\", args);\r\n    return fn(...args);\r\n  };\r\n}\r\n\r\nfunction saveCourse(course) {}\r\n\r\nconst loggedSaveCourse = withLogger(saveCourse);\r\n\r\nloggedSaveCourse({ name: \"JS\", color: \"yellow\" });\r\n```\r\n\r\n\u003Chr />\r\n\r\n## Conclusion\r\n\r\nLes **design patterns** sont des outils puissants, à condition d’être utilisés\r\ndans le **bon contexte** et de manière réfléchie. On peut y penser **en\r\namont**, lors de la conception, si l’on est à l’aise, ou bien **les introduire\r\nprogressivement** en refactorant le projet au fil du temps.\r\n\r\nIls permettent d’**éviter la répétition**, de **faire évoluer** le code plus\r\nfacilement, de **l’améliorer** et surtout de **mieux le tester**.\r\n\r\nDans cet article, nous avons vu comment **certains modèles** comme le\r\n**Singleton**, la **Factory Method**, ou la **Facade** peuvent s’appliquer\r\n**directement** dans une architecture moderne comme React + Zustand. D’autres\r\npatterns plus **conceptuels** (Builder, Strategy, Decorator) ont été illustrés\r\nsous forme de **pseudo-code** afin de mieux saisir leur intention.\r\n\r\n### En bref :\r\n\r\n- Les patterns ne sont pas une contrainte, mais une **liberté maîtrisée**.\r\n- Ils vous permettent d’**éviter les pièges classiques** du développement à mesure que vos projets prennent de l’ampleur.\r\n- **Apprendre à reconnaître** et à utiliser ces modèles, c’est aussi progresser en **maturité logicielle**.\r\n\r\n\u003C/div>","src/data/blog/qu-est-ce-que-design-pattern.mdx","14acde60bbecc0e7","convolutional-neural-networks",{"id":62,"data":64,"body":75,"filePath":76,"digest":77,"deferredRender":31},{"title":65,"isDraft":15,"taxonomies":66,"thumbnail":71,"summary":72,"pubDate":73,"author":74},"Convolutional neural networks",[67,69],{"id":68,"collection":19},"ia",{"id":70,"collection":19},"deep-learning","/iclh-diagram-convolutional-neural-networks.png","Un réseau neuronal convolutionnel (Convolutional Neural Network, ou CNN) est un type d’algorithme d’apprentissage profond supervisé (deep learning) qui confère à un ordinateur une forme de « vision » : il peut ainsi analyser et reconnaître des objets du monde visuel.",["Date","2025-08-12T00:00:00.000Z"],{"id":26,"collection":27},"**Du sport à la médecine, en passant par les transports et la sécurité…**  \r\nVous êtes-vous déjà demandé comment une caméra de surveillance parvient à reconnaître un visage dans une foule, comment un scanner médical détecte une tumeur dissimulée, ou comment un système suit la trajectoire d'un train avec une précision millimétrique ?\r\n\r\n## Introduction\r\n\r\nUn **réseau neuronal convolutionnel** (_Convolutional Neural Network_, ou CNN) est un type d'algorithme d'apprentissage profond supervisé (_deep learning_) qui confère à un ordinateur une forme de « vision » : il peut ainsi analyser et reconnaître des objets du monde visuel.\r\n\r\nLe **réseau neuronal convolutionnel** (_Convolutional Neural Network_, CNN), par analogie, se réfère au fonctionnement des réseaux neuronaux biologiques et constitue, par conséquent, une extension du réseau neuronal artificiel (_Artificial Neural Network_, ANN). Il trouve ses applications principalement dans la reconnaissance et l'analyse d'images.\r\n\r\nEn s'appuyant sur les principes de l'algèbre linéaire, et plus particulièrement sur la manipulation de matrices, les réseaux neuronaux convolutionnels appliquent des opérations de convolution et de transformation afin de détecter et extraire des motifs pertinents au sein d'une image.\r\n\r\n## Comment fonctionne le CNN\r\n\r\nLe fonctionnement d'un **réseau neuronal convolutionnel** (_Convolutional Neural Network_, CNN) repose sur une architecture composée de trois types de couches principales. Ces couches traitent en entrée (_input_) des données structurées spatialement, telles que des images, des spectrogrammes audio ou des séquences vidéo :\r\n\r\n- **Couche convolutionnelle** (_Convolutional layer_)\r\n- **Couche de sous-échantillonnage ou de pooling** (_Pooling layer_)\r\n- **Couche entièrement connectée** (_Fully connected layer_)\r\n\r\n## **Couche convolutionnelle (Convolutional layer)**\r\n\r\nLa couche convolutionnelle est le cœur principal du réseau de neurones, c'est là où la majorité des calculs sont effectués. Son fonctionnement nécessite des composants tels que :\r\n\r\n- Des données d'entrée (input data)\r\n- Un filtre (noyau ou kernel)\r\n- Une carte de caractéristiques (feature map)\r\n\r\n### Fonctionnement :\r\n\r\n- **Convolution** (produit scalaire)\r\n- **ReLU** (supprime les valeurs négatives)\r\n- **Pooling** (réduction de taille)\r\n- Répéter ces étapes\r\n- **Classification finale**\r\n\r\n**Données d'entrée (Input)** : Prenant pour entrée une image de taille 24×24 pixels, qui sera transformée en matrice de pixels 3D correspondant au nombre de pixels respectifs de l'image. Cela veut dire que l'input (la donnée d'entrée) est représenté en hauteur, largeur et profondeur qui correspondent aux caractéristiques RVB de l'image.\r\n\r\n**Filtre (noyau)** : Le filtre est une matrice de poids qui se déplace sur l'image afin d'en détecter les formes et caractéristiques. Ce processus est connu sous le nom d'opération de convolution.\r\n\r\n- Les contours\r\n- Les lignes\r\n- Les textures\r\n- Les formes géométriques\r\n- Des caractéristiques plus complexes dans les couches profondes\r\n\r\nSa taille peut varier, bien que par défaut elle soit de 3×3, il en existe des 5×5, ou 7×7 pixels. Le **champ récepteur** correspond à la zone de l'image d'entrée qui influence un neurone de sortie.\r\n\r\nLe filtre est placé sur une zone de l'image et le produit scalaire est calculé en fonction des pixels d'entrée et du filtre. Cette valeur est alors sauvegardée dans une carte de caractéristiques (feature map). Après cela, le filtre est alors déplacé d'un pas, répétant le processus jusqu'à ce que toute la surface des pixels de l'image soit traitée.\r\n\r\nCertains hyper-paramètres du filtre restent fixes durant le processus, par contre les **poids** sont ajustés afin de maximiser les performances via les opérations de rétropropagation et de descente de gradient. Il existe trois hyper-paramètres qui sont primordiaux dans l'obtention d'un résultat favorable et qui influencent le volume de sortie (output) ; ils doivent être définis bien avant le processus.\r\n\r\n1. **Number of filters (nombre de filtres)** : Affecte la profondeur de la sortie. Par exemple, trois filtres distincts produiraient trois cartes de caractéristiques différentes, créant ainsi une profondeur de trois. _Chaque filtre agit comme un détecteur spécialisé (contours, textures, formes) et produit sa propre carte de caractéristiques, ces cartes s'empilent pour former la profondeur de sortie._\r\n\r\n2. **Stride (pas ou foulée)** : Est la distance, ou le nombre de pixels, sur laquelle le noyau se déplace sur la matrice d'entrée. Bien que des valeurs de foulée de deux ou plus soient rares, une foulée plus grande donne une sortie plus petite. _Une foulée de 1 signifie que le filtre se déplace pixel par pixel (examen détaillé), tandis qu'une foulée de 2 fait sauter un pixel à chaque déplacement (examen plus rapide, image plus petite)._\r\n\r\n3. **Zero-padding (rembourrage zéro)** : Est généralement utilisé lorsque les filtres ne correspondent pas à l'image d'entrée. Cela met à zéro tous les éléments qui se trouvent en dehors de la matrice d'entrée, produisant une sortie plus grande ou de taille égale. Il existe trois types de rembourrage :\r\n\r\n   - **Rembourrage valide :** C'est ce qu'on appelle également l'absence de rembourrage. Dans ce cas, la dernière convolution est abandonnée si les dimensions ne s'alignent pas. _(Si les pièces du puzzle ne rentrent pas au bord, on les abandonne)_\r\n   - **Rembourrage identique :** Ce remplissage garantit que la couche de sortie a la même taille que la couche d'entrée. _(On ajoute des pièces vides autour pour que tout rentre parfaitement)_\r\n   - **Rembourrage complet :** Ce type de remplissage augmente la taille de la sortie en ajoutant des zéros à la bordure de l'entrée. _(On ajoute encore plus de pièces vides pour obtenir une image plus grande)_\r\n\r\n**Après l'opération de convolution, le CNN applique immédiatement la fonction ReLU** (**Re**ctified **L**inear **U**nit - Unité Linéaire Rectifiée). Cette fonction d'activation agit comme un filtre sélectif qui élimine les signaux faibles (valeurs négatives) pour ne conserver que les activations significatives (valeurs positives).\r\n\r\n\u003Cimg src=\"/Relu-activation-function.webp\" alt=\"Fonction d'activation ReLU\" />\r\n\r\n**Principe de fonctionnement :**\r\n\r\n- Valeur positive → conservée telle quelle\r\n- Valeur négative → transformée en zéro\r\n\r\n**Formule :** ReLU(x) = max(0, x)\r\n\r\n**Exemple pratique :**\r\nCarte de caractéristiques avant ReLU : `[-2, 5, -1, 8, -3, 4]`\r\nCarte de caractéristiques après ReLU : `[0, 5, 0, 8, 0, 4]`\r\n\r\n**Impact sur l'apprentissage :** L'introduction de cette non-linéarité est cruciale car elle permet au réseau de modéliser des relations complexes entre les caractéristiques. Sans ReLU, le CNN serait limité à des transformations linéaires et ne pourrait pas détecter des motifs sophistiqués comme les relations spatiales entre les éléments d'un visage (distance œil-nez, configuration bouche-joues) ou d'autres subtilités visuelles complexes.\r\n\r\nCette étape transforme donc un simple calcul mathématique en un véritable processus de reconnaissance intelligent.\r\n\r\n\u003Cimg\r\n  src=\"/iclh-diagram-convolutional-neural-networks.png\"\r\n  alt=\"Diagramme des réseaux neuronaux convolutionnels\"\r\n/>\r\n\r\n### Couche convolutive supplémentaire\r\n\r\nIl est fréquent qu'une hiérarchisation de couches soit appliquée pour analyser progressivement la complexité croissante d'une image. Cette architecture en cascade permet à la structure du CNN de s'adapter intelligemment : les couches ultérieures peuvent exploiter les informations des champs récepteurs des couches précédentes, créant ainsi une véritable hiérarchie de détection.\r\n\r\n**Principe de la hiérarchie des caractéristiques :**\r\n\r\n- **Couches initiales** : Détectent les caractéristiques de bas niveau (contours, lignes, textures simples)\r\n- **Couches intermédiaires** : Combinent ces éléments pour identifier des formes plus complexes (angles, courbes, motifs géométriques)\r\n- **Couches profondes** : Reconnaissent des parties d'objets spécifiques (roues, guidons, cadres)\r\n- **Couches finales** : Assemblent ces parties pour identifier l'objet complet (vélo, voiture, visage)\r\n\r\n**Exemple concret :** Prenons la reconnaissance d'un vélo. Le CNN procède par étapes :\r\n\r\n1. Détection des cercles et lignes droites\r\n2. Identification de formes circulaires (roues potentielles)\r\n3. Reconnaissance du guidon et du cadre\r\n4. Association finale : \"roues + guidon + cadre = vélo\"\r\n\r\nCette approche hiérarchique permet au réseau de construire une compréhension progressive de l'image, où chaque couche affine et enrichit l'analyse de la précédente. In fine, la couche convolutionnelle convertit l'image en valeurs numériques structurées, permettant au réseau neuronal d'interpréter et d'extraire les motifs pertinents pour la classification finale.\r\n\r\n\u003Cimg src=\"/hierarchy.png\" alt=\"Hiérarchie des caractéristiques CNN\" />\r\n\r\n## **Couche de sous-échantillonnage ou de pooling** (_Pooling layer_)\r\n\r\nDans cette étape du processus CNN, les informations collectées sont réduites et regroupées afin de diminuer la dimensionnalité des données. Dans le même processus que la couche convolutive, elle applique un filtre qui, à l'inverse de la couche convolutive, n'a pas de poids. Une fonction d'agrégation est appliquée aux valeurs du champ récepteur afin de remplir le tableau de sortie. **Cette fonction d'agrégation constitue le paramètre principal configurable qui détermine le type de pooling utilisé.**\r\n\r\n**Objectifs principaux :**\r\n\r\n- Réduire la taille des données\r\n- Diminuer le nombre de paramètres\r\n- Conserver les caractéristiques importantes\r\n\r\n**Les deux principaux types de pooling (fonctions d'agrégation) :**\r\n\r\n**1. Max Pooling (Regroupement maximal) :**\r\n\r\n- Fonction d'agrégation : `f(région) = max(valeurs)`\r\n- Sélectionne la **valeur maximale** dans chaque région du champ récepteur\r\n- Conserve les caractéristiques les plus saillantes\r\n- Plus couramment utilisé car il préserve les contours et détails importants\r\n\r\n**2. Average Pooling (Regroupement moyen) :**\r\n\r\n- Fonction d'agrégation : `f(région) = moyenne(valeurs)`\r\n- Calcule la **moyenne arithmétique** de toutes les valeurs dans le champ récepteur\r\n- Lisse les données en réduisant le bruit\r\n- Moins utilisé mais utile pour certaines applications spécifiques\r\n\r\n## Visualisation\r\n\r\n#### Région 2×2 organisée comme une matrice :\r\n\r\n\u003Cimg\r\n  src=\"/Sans-titre-2025-06-23-2323 (2).png\"\r\n  alt=\"Région 2x2 organisée en matrice\"\r\n/>\r\n\r\n## Calculs selon le type de pooling :\r\n\r\n**Max Pooling :**\r\n\r\n- On regarde toutes les valeurs : `1, 3, 2, 4`\r\n- On prend la **plus grande** : `max(1, 3, 2, 4) = 4`\r\n- **Résultat : 4**\r\n\r\n**Average Pooling :**\r\n\r\n- On additionne toutes les valeurs : `1 + 3 + 2 + 4 = 10`\r\n- On divise par le nombre de valeurs : `10 ÷ 4 = 2.5`\r\n- **Résultat : 2.5**\r\n\r\n## Visualisation du processus :\r\n\r\n\u003Cimg\r\n  src=\"/Sans-titre-2025-06-23-2323 (3).png\"\r\n  alt=\"Visualisation du processus de pooling\"\r\n/>\r\n\r\nLe filtre de pooling \"regarde\" cette région 2×2 et la **résume en une seule valeur** selon la fonction d'agrégation choisie.\r\n\r\nCes paramètres (type de fonction d'agrégation, taille du filtre, stride) sont configurables avant l'entraînement selon les besoins spécifiques du modèle, permettant d'adapter le comportement du pooling à la tâche de classification visée.\r\n\r\n## **Couche entièrement connectée** (_Fully connected layer_)\r\n\r\nCette couche effectue une classification en fonction des caractéristiques extraites des couches précédentes et de leurs filtres. Elle applique une fonction d'activation (généralement **softmax**) qui permet de convertir les données en **probabilités** : chaque classe possible reçoit un score entre 0 et 1, et la **somme de toutes les probabilités égale 1**.\r\n\r\n### Exemple :\r\n\r\nPour reconnaître des animaux :\r\n\r\n- Chat : 0.7 (70% de probabilité)\r\n- Chien : 0.2 (20% de probabilité)\r\n- Oiseau : 0.1 (10% de probabilité)\r\n- **Total : 0.7 + 0.2 + 0.1 = 1.0**\r\n\r\nLa classe avec la **plus haute probabilité** (ici \"Chat\" avec 0.7) est la prédiction finale.\r\n\r\n## Conclusion\r\n\r\nLes **réseaux neuronaux convolutionnels** (CNN) constituent une architecture d'apprentissage profond particulièrement efficace pour le traitement et l'analyse d'images. Leur fonctionnement repose sur trois composants principaux : les couches convolutionnelles qui extraient les caractéristiques, les couches de pooling qui réduisent la dimensionnalité, et les couches entièrement connectées qui effectuent la classification finale.\r\n\r\n### Architecture et performances\r\n\r\nCette structure hiérarchique permet aux CNN de détecter progressivement des motifs de plus en plus complexes, depuis les contours simples jusqu'aux objets complets. Les hyper-paramètres configurables (nombre de filtres, stride, padding) offrent une flexibilité d'adaptation selon les besoins spécifiques de chaque application.\r\n\r\n### Applications pratiques\r\n\r\nLes CNN trouvent aujourd'hui des applications concrètes dans de nombreux secteurs : diagnostic médical par imagerie, systèmes de surveillance automatisée, contrôle qualité industriel, et véhicules autonomes. Leur capacité à traiter efficacement de grandes quantités de données visuelles en fait un outil incontournable pour ces domaines.\r\n\r\n### Perspectives techniques\r\n\r\nL'optimisation continue des architectures CNN, combinée à l'amélioration des capacités de calcul, permet d'envisager des applications plus complexes et une précision accrue dans les tâches de reconnaissance d'images. La compréhension de ces mécanismes fondamentaux reste essentielle pour développer et implémenter efficacement ces solutions technologiques.","src/data/blog/convolutional-neural-networks.mdx","354dbc9032e737c2","global-id",{"id":78,"data":80,"body":89,"filePath":90,"digest":91,"deferredRender":31},{"title":81,"isDraft":15,"taxonomies":82,"thumbnail":85,"summary":86,"pubDate":87,"author":88},"Global Identifier",[83],{"id":84,"collection":19},"architecture-design","/global_id/GlobalID.png","La génération d'identifiants dans une application est un besoin métier très courant. Que ce soit pour créer des bons de commande, des utilisateurs ou toute autre entité métier, chaque objet a besoin d’un identifiant unique et traçable.",["Date","2025-09-04T00:00:00.000Z"],{"id":26,"collection":27},"La génération d'identifiants dans une application est un besoin métier très courant. Que ce soit pour créer des bons de commande, des utilisateurs ou toute autre entité métier, chaque objet a besoin d’un identifiant **unique et traçable**. Ce besoin devient crucial lorsque l’application commence à **scaler horizontalement** (multiplication des instances, microservices, etc.).\r\n\r\nDans une application classique, on utilise souvent des identifiants auto-incrémentés ou des UUID. Cependant, ces méthodes présentent des limites :\r\n\r\n- Les identifiants incrémentaux sont **hautement prévisibles** (ce qui peut permettre, par exemple, d’estimer le nombre total de commandes ou d’accéder à des ressources non autorisées).\r\n- Les UUID, bien qu’un peu plus sûrs, peuvent être trop longs, peu optimisés pour certaines bases de données, ou encore manquer de **structure métier**.\r\n\r\nUne approche plus structurée et sécurisée devient donc nécessaire pour générer des identifiants **robustes, non prévisibles et compatibles avec une architecture distribuée**.\r\n\r\n## Les limites d’une approche classique\r\n\r\n### Auto-incrémentation\r\n\r\n- Très prévisible : ces identifiants suivent un ordre strict et séquentiel, ce qui les rend facilement devinables. Un attaquant peut ainsi estimer le volume de données (nombre de commandes, d’utilisateurs, etc.), ou tenter des accès non autorisés par simple incrémentation.\r\n\r\n### UUID (notamment UUIDv4)\r\n\r\n- **Poids élevé** : un UUIDv4 occupe 16 octets, contre 4 octets pour un entier auto-incrémenté (INT). Ce surcoût impacte :\r\n  - les performances de la base de données (indexation, tri, recherche)\r\n  - l’utilisation mémoire côté application, surtout à grande échelle\r\n- **Peu lisible et difficile à manipuler** :\r\n  - les UUID sont longs, sans structure lisible et difficiles à interpréter pour un humain.\r\n  - ils compliquent le debug, l’affichage dans les interfaces, ou la construction d’URLs propres.\r\n  - ils ne portent aucune information métier (type d’entité, date de création, tenant, etc.).\r\n- **Risque (théorique) de collision** :\r\n  - bien que rares, les collisions restent possibles si la source d’aléatoire est défaillante.\r\n  - même avec un espace d'identifiants très large (128 bits → 3.4 × 10³⁸ possibilités), une application à très haute volumétrie peut atteindre des seuils où ces risques deviennent réels.\r\n\r\n## Présentation du GID\r\n\r\n### Définition\r\n\r\nUn **Global ID (GID)** est une représentation unique d’une entité dans une application. Il permet d’identifier de manière fiable et traçable n’importe quel objet métier (utilisateur, commande, document, etc.), tout en tenant compte du **contexte du tenant** (par exemple une organisation ou un client dans une application multi-tenant).\r\n\r\n**NB :** un _tenant_ représente une organisation ou un client dans une application _multi-tenant_ (c’est-à-dire une application utilisée par plusieurs organisations).\r\n\r\n### Objectif et justification\r\n\r\nDans cet article, nous allons manipuler un GID de **24 octets**. Ce format n’est pas un standard : la plupart des technologies utilisent plutôt **16 octets**, tel que défini par les normes **ISO/IEC 11578:1996**, **ITU-T Rec. X.667** et le **RFC 4122** (spécification des UUID).\r\n\r\nNous faisons le choix d’un GID sur **24 octets (192 bits)** pour répondre à des besoins spécifiques :\r\n\r\n- garantir une **unicité globale renforcée**,\r\n- inclure directement des **informations métier** (tenant, type d’entité, timestamp, etc.) dans la structure de l’identifiant.\r\n- Optimiser pour le multi-tenant : éviter les jointures coûteuses pour identifier le tenant d'une entité\r\n\r\n**Concernant l'impact performance :** bien que 24 octets soient plus lourds qu'un UUID standard (16 octets), les informations métier intégrées permettent d'éviter de nombreuses jointures SQL, compensant largement ce surcoût. De plus, l'indexation reste efficace grâce à la structure prévisible.\r\n\r\n## Anatomie du GID (explication binaire)\r\n\r\n### Notions de base\r\n\r\n- **Bit** : la plus petite unité de données, représentant une valeur binaire (0 ou 1).\r\n- **Octet** : un regroupement de 8 bits, suffisant pour représenter un caractère ou un élément de données complet.\r\n\r\nEn analogie :\r\n\r\n- un **bit** est comme une lettre élémentaire\r\n- un **octet** est le plus petit “mot” que l’ordinateur peut manipuler directement.\r\n\r\nDonc :\r\n\r\n- 2 octets = 16 bits (2 × 8)\r\n- 8 octets = 64 bits (8 × 8)\r\n- 24 octets = 192 bits (24 × 8)\r\n\r\n**Formule générale :**\r\n\r\n\u003Cimg src=\"/global_id/formule.png\" alt=\"Formule générale\" />\r\n\r\n## Cas pratique\r\n\r\nNous allons implémenter un **GID de 24 octets** avec Go, dans un **système multi-tenant**. Chaque bloc de l’identifiant se voit attribuer une plage précise pour reconstituer les 24 octets\r\n\r\n| Octets | Contenu     | Taille             |\r\n| ------ | ----------- | ------------------ |\r\n| 0-7    | Tenant ID   | 8 octets (64 bits) |\r\n| 8-9    | Entity Type | 2 octets (16 bits) |\r\n| 10-17  | Timestamp   | 8 octets (64 bits) |\r\n| 18-23  | Random      | 6 octets (48 bits) |\r\n\r\nAinsi, le GID contient à la fois des informations métier (tenant, type), un timestamp pour la traçabilité, et des données aléatoires pour garantir l’unicité globale.\r\n\r\n### 1. Déclaration des variables\r\n\r\n\u003Cbr />\r\n\r\n```go\r\npackage gid\r\n\r\nimport (\r\n    \"crypto/rand\"\r\n    \"encoding/binary\"\r\n    \"encoding/hex\"\r\n    \"fmt\"\r\n    \"strings\"\r\n    \"time\"\r\n)\r\n\r\nconst (\r\n    GIDSize = 24 // 192 bits au total\r\n)\r\n\r\ntype (\r\n    GID      [GIDSize]byte // GID = tableau de 24 octets\r\n    TenantID [8]byte       // Tenant sur 8 octets\r\n)\r\n\r\n```\r\n\r\n### 2. Initialisation du GID\r\n\r\n\u003Cbr />\r\n\r\n```go\r\npackage gid\r\n\r\nfunc NewGID(tenantID TenantID, entityType uint16) {\r\n    var id GID // on initialise un tableau de 24 octets pour notre GID\r\n}\r\n```\r\n\r\n### 3. Séparation des blocs et construction\r\n\r\n\u003Cbr />\r\n\r\n```go\r\npackage gid\r\n\r\nfunc NewGID(tenantID TenantID, entityType uint16) (GID, error) {\r\n    var id GID\r\n\r\n    // 1. Tenant ID (octets 0 à 7)\r\n    // On copie les 8 octets de tenantID dans les 8 premiers octets de id\r\n    copy(id[0:8], tenantID[:])\r\n\r\n    // 2. Entity Type (octets 8 à 9)\r\n    // - entityType est un uint16 (16 bits = 2 octets)\r\n    // - On l'encode en bytes Big Endian et on l'écrit dans id[8] et id[9]\r\n    binary.BigEndian.PutUint16(id[8:10], entityType)\r\n\r\n    // 3. Timestamp (octets 10 à 17)\r\n    // - On récupère le timestamp actuel en millisecondes\r\n    // - On le convertit en uint64 (64 bits = 8 octets)\r\n    // - On écrit ces 8 octets dans id[10] à id[17]\r\n    now := time.Now().UnixMilli()\r\n    binary.BigEndian.PutUint64(id[10:18], uint64(now))\r\n\r\n    // 4. Données aléatoires (octets 18 à 23)\r\n    // - Ces 6 octets servent à garantir l'unicité globale du GID\r\n    // - On les remplit avec des bytes aléatoires\r\n    _, err := rand.Read(id[18:24])\r\n    if err != nil {\r\n        return Nil, fmt.Errorf(\"failed to generate random bytes: %v\", err)\r\n    }\r\n\r\n    return id, nil\r\n}\r\n```\r\n\r\n## Avantages du GID\r\n\r\n1. **Traçabilité native** : timestamp intégré pour audit et debug\r\n2. **Context-aware** : tenant et type d'entité directement accessibles\r\n3. **Performances** : évite les jointures pour identifier le contexte\r\n4. **Sécurité** : non-prévisible grâce à la partie aléatoire\r\n5. **Flexibilité** : format structuré mais extensible\r\n\r\n## Conclusion\r\n\r\nLe code présenté ici est spécifique à Go, mais le **concept du GID** peut être transposé dans n’importe quel langage.\r\n\r\nL’objectif principal est de **visualiser comment représenter un identifiant global (GID) de manière informative**, en regroupant des **données métier concrètes** (tenant, type d’entité, timestamp) tout en garantissant :\r\n\r\n- **l’unicité globale**,\r\n- et la **résistance à la prédictibilité**.\r\n\r\nAinsi, le GID permet de créer des identifiants à la fois **robustes, traçables et utiles pour le business**, tout en restant **optimisés pour une architecture distribuée ou multi-tenant**.","src/data/blog/global-id.mdx","201b5840fe875ca0",["Map",84,93,52,98,103,104,38,109,54,114,70,119,68,124,21,128,18,133],{"id":84,"data":94,"filePath":96,"digest":97},{"name":95},"Design architecture","src/data/taxonomies/architecture-design.json","08799596a8c6e694",{"id":52,"data":99,"filePath":101,"digest":102},{"name":100},"Bonnes pratiques / Clean code","src/data/taxonomies/bonnes-pratiques-clean-code.json","5eb248901f0855ad","design",{"id":103,"data":105,"filePath":107,"digest":108},{"name":106},"Design systems","src/data/taxonomies/design.json","2cbf2cbe6dd8265f",{"id":38,"data":110,"filePath":112,"digest":113},{"name":111},"Infrastructure & Réseaux","src/data/taxonomies/infrastructure-reseaux.json","1435d47967707102",{"id":54,"data":115,"filePath":117,"digest":118},{"name":116},"Programmation","src/data/taxonomies/programmation.json","04499f26ce00c5d9",{"id":70,"data":120,"filePath":122,"digest":123},{"name":121},"Deep learning","src/data/taxonomies/deep-learning.json","fbf840517b1dcaee",{"id":68,"data":125,"filePath":126,"digest":127},{"name":68},"src/data/taxonomies/ia.json","05c1796405534d48",{"id":21,"data":129,"filePath":131,"digest":132},{"name":130},"Graphic Design","src/data/taxonomies/graphic-design.json","7bb9a482bad2297a",{"id":18,"data":134,"filePath":136,"digest":137},{"name":135},"Digital / UX/UI Design","src/data/taxonomies/digital-ux-ui-design.json","3191f7292d0b051b",["Map",139,140,145,146,26,152],"ben-holmes",{"id":139,"data":141,"filePath":143,"digest":144},{"name":139,"portfolio":142},"https://ben_holmes.com","src/data/authors/ben-holmes.json","c3bccad803421701","durand-construction",{"id":145,"data":147,"filePath":150,"digest":151},{"name":148,"portfolio":149},"Durand-construction","https://durand-construction.com","src/data/authors/durand-construction.json","efca6d7c0b5fda3d",{"id":26,"data":153,"filePath":155,"digest":156},{"name":26,"portfolio":154},"https://eembouz.com/","src/data/authors/elysee.json","82d1d622aa6ee2b6"]